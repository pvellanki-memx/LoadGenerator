= FRS: Surveillance Engine Functional Requirements
:sectnums:
:toc:

== Overview

The Surveillance Engine is a critical component of the Trading Surveillance System. Its primary function is to analyze trade and order data in real-time to detect and alert on potential market abuses and irregularities in trading activities. The functional requirements outlined here align with the objectives and scope detailed in the Surveillance BRD.

== Functional Requirements

=== FR1: Data Ingestion and Normalization
- FR1.1: The engine must ingest real-time trade and order data continuously with no data loss.
- FR1.2: Data normalization must conform to a predefined schema to ensure consistency across all data points.

=== FR2: Benchmarking Integration
- FR2.1: The engine shall integrate with the Benchmarking module to retrieve current benchmark parameters for various trade instruments.
- FR2.2: It should automatically adjust the detection algorithms based on updated benchmark data.

=== FR3: Pattern Recognition and Anomaly Detection
- FR3.1: Must identify known patterns of market manipulation, such as spoofing, wash trades, and layering, based on configurable rules and benchmarks.
- FR3.2: Should use statistical analysis to detect anomalies that could indicate market manipulation or irregularities.

=== FR4: Alert Generation
- FR4.1: The engine is required to generate alerts for any detected activities that deviate from the benchmark or match known patterns of market abuse.
- FR4.2: Each alert must include relevant details such as security identifier, timestamp, and a description of the detected irregularity.

=== FR5: Real-Time Processing
- FR5.1: Real-time data processing should occur with minimal latency to enable timely detection and alerting.
- FR5.2: Must support processing and analysis of data across multiple trading venues simultaneously.

=== FR6: Scalability
- FR6.1: The engine must be scalable to handle increasing volumes of data without degradation in performance.
- FR6.2: Should provide mechanisms to scale horizontally, adding more processing power as the data volume increases.

=== FR7: Historical Data Analysis
- FR7.1: Should have the capability to analyze historical data for back-testing and refining detection algorithms.
- FR7.2: Must maintain a historical database of alerts and outcomes to improve future detection accuracy.

=== FR8: User-Defined Rules and Parameters
- FR8.1: Must allow regulatory users to configure and modify the rules and parameters used for market abuse detection.
- FR8.2: Should include a user-friendly interface for setting these parameters without needing to change the underlying code.

=== FR9: Reporting and Audit Trails
- FR9.1: The engine must record all generated alerts along with decisions and actions taken as a result.
- FR9.2: Must provide comprehensive reporting capabilities for auditing and compliance purposes.

=== FR10: Fault Tolerance and Reliability
- FR10.1: Must have failover capabilities to ensure continuous operation.
- FR10.2: Should maintain data integrity and provide accurate processing outcomes even in the event of partial system failures.

== Validation Criteria

Each functional requirement will have associated validation tests to ensure they are met. The system will be subjected to various scenarios, including simulated market conditions, to validate the accuracy and efficiency of the Surveillance Engine.

== Compliance and Performance Standards

The Surveillance Engine must comply with relevant financial industry regulations and standards. It must also meet defined performance benchmarks, including but not limited to processing latency and alert accuracy rates.




= SPEC-02: Trading Surveillance System with Benchmarking
:sectnums:
:toc:

== Background

The enhanced Trading Surveillance System is an advanced solution designed for real-time monitoring of trading activities, with an emphasis on data-driven benchmarking to identify anomalies and potential manipulative behaviors. This system integrates a sophisticated benchmarking process to calibrate the surveillance algorithms, leveraging InfluxDB for time-series data storage, enabling efficient and rapid detection of unusual patterns.

== Requirements

=== Functional Requirements
- Benchmark-based alerting for identifying deviations from established trading patterns.
- Real-time analysis of trades against historical data in InfluxDB.
- Intuitive User Interface for surveillance monitoring and alert management.
- Efficient workflow for alert investigation and case management.

=== Non-Functional Requirements
- Benchmarking process should be automated and run at configurable intervals.
- The Surveillance Engine must process data with minimal latency.
- The User Interface should provide real-time updates without perceptible delay.
- Alert Management & Workflow system must support concurrent use by multiple operators.

== Method

=== Architecture Overview
The system is composed of distinct but interconnected components:
- **Benchmarking**: Sets the baseline for normal trading activities.
- **InfluxDB**: Stores time-series data used for benchmarking and real-time analysis.
- **Surveillance Engine**: Analyzes streaming data, compares against benchmarks, and generates alerts.
- **User Interface**: Allows users to view and manage alerts.
- **Alert Management & Workflow**: Manages the lifecycle of alerts and supports case investigation processes.

=== Component Design

==== Benchmarking
- Determines thresholds and patterns that represent normal trading behavior.
- Periodically updates to adapt to changing market conditions.
- Supplies the Surveillance Engine with dynamic parameters for anomaly detection.

==== InfluxDB
- Stores granular trade and order data with precise timestamping.
- Provides fast querying capabilities for real-time analytics.
- Serves as the historical data repository for the benchmarking process.

==== Surveillance Engine
- Processes data streams in real-time, leveraging benchmarks for anomaly detection.
- Generates alerts for activities that significantly deviate from the benchmark.
- Integrates with InfluxDB for continuous data retrieval and analysis.

==== User Interface
- Displays a dashboard for real-time surveillance updates.
- Provides tools for configuring benchmark parameters and alert thresholds.
- Offers investigative functionalities for deep dives into specific alerts.

==== Alert Management & Workflow
- Tracks the status of each alert from generation to resolution.
- Supports assignment, acknowledgment, and documentation of investigative actions.
- Integrates audit trails for compliance and retrospective analysis.

== Implementation

The implementation process follows the WBS structure with specified tasks and timelines.

=== System Setup and Configuration
Involves configuring InfluxDB, setting up the benchmarking module, and establishing the initial parameters for the Surveillance Engine.

=== Development
Encompasses the development of the Surveillance Engine with benchmarking integration, the User Interface design and creation, and the Alert Management & Workflow system.

=== Integration and Testing
Focuses on integrating all components, ensuring data flows correctly, and validating the functionality of the entire system.

=== Deployment
Includes staging and production deployment, ensuring the system is operational and ready for use.

== Milestones
- M1: Completion of InfluxDB Setup and Benchmarking Integration
- M2: Development of Surveillance Engine and UI Completion
- M3: Full System Integration
- M4: Successful Staging Deployment
- M5: Production Deployment and System Go-Live
- M6: Post-Deployment Review and Operational Handoff

== Gathering Results
Evaluates system performance based on the accuracy and efficiency of alert generation, benchmarking effectiveness, and user feedback on the Interface and Workflow system.













import pandas as pd
import sqlite3
import sys
import os

db_name = sys.argv[1]
# Connect to the SQLite database
conn = sqlite3.connect(db_name)

# Query the data from the grouped_trades table
query = "SELECT * FROM grouped_trades"
grouped_trade_data_frame = pd.read_sql_query(query, conn)

# Close the database connection
conn.close()

# Symbols to handle separately
symbols = ['SPY', 'QQQ', 'TSLA', 'AAPL', 'NVDA', 'IWM']

# Base file name from the database name
base_file_name = db_name[5:10]

# Loop through each symbol and save the corresponding CSV
for symbol in symbols:
    df_filtered = grouped_trade_data_frame[grouped_trade_data_frame['SYM'] == symbol]
    output_file_name = f'summary_trade_data_{base_file_name}_{symbol}.csv'
    df_filtered.to_csv(output_file_name, index=False)

# Handle all other symbols
other_symbols_df = grouped_trade_data_frame[~grouped_trade_data_frame['SYM'].isin(symbols)]
output_file_name = f'summary_trade_data_{base_file_name}_OTHERS.csv'
other_symbols_df.to_csv(output_file_name, index=False)

print("Data from grouped_trades has been successfully processed and saved.")



http://ec2-35-170-218-11.compute-1.amazonaws.com/



gc22022.ex10.ewr2.memx.tech:2005 primary_boats_general> actors.STREAM_BOATS.actors.SYMBOL_ADMIN.updatePriorDayClosingPrice SYMBOL-ID=ZTEST CLOSE-PRICE=10

ifconfig mext.740:40024 10.12.68.108/22
arping -c 2 -U -I mext.740:40024 10.12.68.108 &
