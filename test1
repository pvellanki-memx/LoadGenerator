#!/bin/bash

current_date=$(date +"%Y-%m-%d")
date=$(date -d "$current_date - 1 day" +"%Y-%m-%d")

mm_dd=$(date -d "$date" +"%m-%d")

# Create the output directory if it doesn't exist
output_dir="/mnt/occ/orsa-summary"
mkdir -p "$output_dir"

# Define the directory where the files are located
base_dir="/mnt/occ/downloads/prod"

# Construct the file name using the provided date
compressed_file_to_watch="memx_orsa_trades_$date.xml.Z"

# Define the monitor folder
monitor_folder="$base_dir"

# Check if the file exists, wait up to 10 times
retries=10
while [ ! -e "$monitor_folder/$compressed_file_to_watch" ] && [ $retries -gt 0 ]; do
    echo "$compressed_file_to_watch not found in $monitor_folder. Waiting..."
    sleep 10  # Adjust the interval as needed
    ((retries--))
done

if [ $retries -eq 0 ]; then
    echo "Compressed file not found after 10 retries. Exiting."
    exit 1
fi

echo "Found $compressed_file_to_watch"

# Uncompress the file and wait for it to complete
echo "Uncompressing $compressed_file_to_watch..."
zcat "$monitor_folder/$compressed_file_to_watch" > "$monitor_folder/memx_orsa_trades_$date.xml"
uncompress_pid=$!

wait "$uncompress_pid"

# Check if the XML file is complete by examining the last two lines
last_two_lines=$(zcat "$monitor_folder/$compressed_file_to_watch" | tail -n 2)

if [[ $last_two_lines != *"</FIXML>"* ]]; then
    echo "XML file is not complete. Missing </FIXML> tag."
    exit 1
fi

# Define a function to execute trades and exchange recon
execute_trades_and_recon() {
    # Add the content of run_trades.sh here
    echo "Executing run_trades.sh..."
    db_name="$date.db"

    # Step 1: Split the big XML file using split.py
    python3 split_v4.py "$base_dir"/memx_orsa_trades_"$date".xml "$date"

    # Step 2: Process each split file using xml_to_db.py
    for split_file in "$date"_*; do
        python3 xml_2_db_v5.py "$split_file" "$db_name" > log.txt &

        # Capture the PID of the last background process
        pid=$!

        # Wait for the background process to complete
        wait "$pid"

        echo "Processing of $split_file completed."
    done

    # Step 3: Group the data in the database using groupedexcel.py
    python3 groupedexcel_v5.py "$db_name"

    grouped_pid=$!
    # Wait for groupedexcel.py to complete
    wait "$grouped_pid"

    echo "Grouping of data completed."

    # Step 4: Perform further processing using furtherstreaming.py
    python3 streamfurther_v4.py "$db_name"

    streamfurther_pid=$!
    # Wait for groupedexcel.py to complete
    wait "$streamfurther_pid"

    echo "Grouping summary of data completed."


    # Step 4: Perform further processing using furtherstreaming.py
    python3 dump2excel.py "$db_name"

    dump2excel_pid=$!
    # Wait for groupedexcel.py to complete
    wait "$dump2excel_pid"

    echo "Grouping summary csv generated."

    
    echo "Executing run_exchange_recon.sh..."
    db_name="$date.db"

    # Step 1: Group the data in the database using groupedexcel.py
    python3 grouptradesbyexch.py "$db_name"

    groupedbyexch_pid=$!
    # Wait for groupedexcel.py to complete
    wait "$groupedbyexch_pid"

    echo "Grouping by exchange completed."

    # Step 4: Perform further processing using furtherstreaming.py
    python3 streamfurther_v5.py "$db_name"

    SF5_pid=$!
    wait "$SF5_pid"

    echo "grouping summary bu exchange completed"

    python3 exchangrecon.py "$db_name"

    exchangerecon_pid=$!
    wait "$exchangrecon_pid"

    echo "exchange recon against OCC Completed"

    python3 excel.py "$db_name"

    excel_pid=$!
    wait "$excel_pid"

    echo "Common aggregates file generated"
}

# Execute the combined trades and exchange recon function
execute_trades_and_recon

echo "Scripts executed successfully."

mv *"$mm_dd.csv" "$output_dir/"
